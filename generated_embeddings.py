from sentence_transformers import SentenceTransformer
import numpy as np
import os
import time  # <-- import time ajoutÃ©

def load_chunks(file_path="chunks.txt"):
    """Charge les chunks depuis un fichier texte, sÃ©parÃ©s par '---'."""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Le fichier {file_path} est introuvable.")
    with open(file_path, "r", encoding="utf-8") as f:
        raw = f.read()
    chunks = [chunk.strip() for chunk in raw.split('---') if chunk.strip()]
    print(f"ðŸ”¹ {len(chunks)} chunks chargÃ©s depuis {file_path}")
    return chunks

def generate_embeddings(chunks, model_name="sentence-transformers/all-mpnet-base-v2", batch_size=32):
    """GÃ©nÃ¨re les embeddings pour une liste de chunks via SentenceTransformer."""
    model = SentenceTransformer(model_name)
    start = time.time()  # dÃ©but mesure temps
    embeddings = model.encode(chunks, batch_size=batch_size, show_progress_bar=True, convert_to_numpy=True)
    end = time.time()  # fin mesure temps
    print(f"â³ Temps d'encodage : {end - start:.2f} secondes")
    return embeddings

def save_embeddings(embeddings, file_path="embeddings.npy"):
    """Sauvegarde les embeddings au format numpy."""
    np.save(file_path, embeddings)
    print(f"âœ… Embeddings sauvegardÃ©s dans {file_path}")

def main(chunks_file="chunks.txt", embeddings_file="embeddings.npy", force_regen=False):
    if os.path.exists(embeddings_file):
        if force_regen:
            print(f"âš ï¸ {embeddings_file} existe dÃ©jÃ , suppression pour rÃ©gÃ©nÃ©rer.")
            os.remove(embeddings_file)
        else:
            print(f"â„¹ï¸ {embeddings_file} existe dÃ©jÃ . Utilisez force_regen=True pour rÃ©gÃ©nÃ©rer.")
            return

    chunks = load_chunks(chunks_file)
    embeddings = generate_embeddings(chunks)
    save_embeddings(embeddings, embeddings_file)

if __name__ == "__main__":
    # Exemple d'utilisation : 
    # main(force_regen=True)  # pour forcer la rÃ©gÃ©nÃ©ration
    main(force_regen=True)
